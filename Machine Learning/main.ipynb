{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (64, None, 256)           17408     \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (64, None, 68)            69700     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,025,412\n",
      "Trainable params: 4,025,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received incompatible tensor with shape (78, 256) when attempting to restore variable with shape (68, 256) and name layer_with_weights-0/embeddings/.ATTRIBUTES/VARIABLE_VALUE.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m checkpoint_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./training_checkpoints\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     79\u001b[0m checkpoint_prefix \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(checkpoint_dir, \u001b[39m\"\u001b[39m\u001b[39mcheckpoints\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m model\u001b[39m.\u001b[39;49mload_weights(tf\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49mlatest_checkpoint(checkpoint_dir))\n\u001b[1;32m     82\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInput: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mrepr\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(idx2char[input_example_batch[\u001b[39m0\u001b[39m]])))\n\u001b[1;32m     83\u001b[0m \u001b[39mprint\u001b[39m()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/training/saving/saveable_object_util.py:139\u001b[0m, in \u001b[0;36mResourceVariableSaveable.restore\u001b[0;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[1;32m    136\u001b[0m   assigned_variable \u001b[39m=\u001b[39m resource_variable_ops\u001b[39m.\u001b[39mshape_safe_assign_variable_handle(\n\u001b[1;32m    137\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_op, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_shape, restored_tensor)\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 139\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    140\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived incompatible tensor with shape \u001b[39m\u001b[39m{\u001b[39;00mrestored_tensor\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhen attempting to restore variable with shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_shape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mand name \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39mreturn\u001b[39;00m assigned_variable\n",
      "\u001b[0;31mValueError\u001b[0m: Received incompatible tensor with shape (78, 256) when attempting to restore variable with shape (68, 256) and name layer_with_weights-0/embeddings/.ATTRIBUTES/VARIABLE_VALUE."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "path_to_file = tf.keras.utils.get_file(\n",
    "    'shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "\n",
    "text = open('./text.txt', 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "char2idx = {u: i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape,\n",
    "          \"# (batch_size, sequence_length, vocab_size)\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "sampled_indices = tf.random.categorical(\n",
    "    example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"checkpoints\")\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape,\n",
    "      \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "\n",
    "EPOCHS = 1\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n",
    "\n",
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "def generate_text(model, start_string, temperature = 1.0):\n",
    "    num_generate = 1000\n",
    "\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(\n",
    "            predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banu Chrisnadi, [1/5/23 7:40 AM]\n",
      "mas tolong cekkan aplikasi mukab\n",
      "\n",
      "Mbak Raqicine onek raban mastassedan Prtrek HTTPPu dKik antukas soto > taa aDo yang ckpe  rhiripas\n",
      "\n",
      "Nungki Edi Rahmadi, [1/6/23 8:17 AM]\n",
      "mas para b gut lange forense ek espud , peta msso yaan kara luyannyackaban da tar ante\n",
      "\n",
      "Nungki Edi Rya Rahmadi, [1/6/23 11:19 PM]\n",
      "ie\n",
      "\n",
      "Mbak Hadwa, [1/9/23 10:12 AM]\n",
      "kengmape Tb\n",
      "\n",
      "Mus AKPuk masinya mri beruri\n",
      "\n",
      "Om Yayak, [1/6/23 8:33 PM]\n",
      "@yRyay4 > itansa da onte data selu uku da ser heris isi mas heri pikukar.kukapkuk regii\n",
      "\n",
      "Nungki Edi hat jsi dakanin ani ya nias dlre sjongki Petmhsi > httla jsok bervar.ko mpungkinker.js\n",
      "\n",
      "puk SPM/ ketu/s SSKM]\n",
      "Og Kerved:\n",
      "\n",
      "Mbak Rahmadi, [1/5/23 8:46 PM]\n",
      "@y4d_[1/5/23 10:20 AM]\n",
      "ett:\n",
      "\n",
      "Adhitya Putri ntyatannfo War.\n",
      "\n",
      "Darwanyo Edi Rahmadi, [1/5/23 7:46 PM]\n",
      "Oym mas Arbi, [1/5/23 7:38 PM]\n",
      "\n",
      "\n",
      "Raswanto, [1/9/23 8:41 AM]\n",
      "ya\n",
      "\n",
      "Adhituk lau ya?\n",
      "\n",
      "1war Rahma, [1/5/23 9:10 AM]\n",
      "iki dalu info ]\n",
      "\n",
      "Om Yaakinya mas legi mas? kasintar idi, A1bilumah Rahmadi tarah batap.ina nikunan du karah ula dinunni mas lemasi fok pitasintar.id/aptobkok:/T/2. T::\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"banu Chrisnadi, [1/5/23 7:40 AM]\\nmas tolong cekkan aplikasi mukab\\n\\n\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
